# 本地部署具体步骤
## Step1 下载模型
由于有墙的限制，在挂VPN的时候，通过程序下载模型容易被中断很不稳定。
所以我建议直接在huggingface官网上下载模型，然后将指定路径配置到api.py里面
这是模型下载地址[chatglm3-6b](https://huggingface.co/THUDM/chatglm3-6b/tree/main)
### 注意：不要全部下载完，根据下面图片内容下载
![image](https://github.com/langrentaole/local-deploy-chatGLM/assets/109889139/0953e593-c9ab-4361-82e6-c85b11e7381d)


